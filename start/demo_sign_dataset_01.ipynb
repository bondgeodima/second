{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "ROOT_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "# Import COCO config\n",
    "#sys.path.append(os.path.join(ROOT_DIR, \"/samples/coco/\"))  # To find local version\n",
    "#import coco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(ROOT_DIR, \"\"))  # To find local version\n",
    "from samples.coco import coco\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "# single sign detect\n",
    "#COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_road_sign.h5\")\n",
    "\n",
    "# detect signs by type\n",
    "#COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_road_signs.h5\")\n",
    "\n",
    "# detect signs by type\n",
    "# COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_road_signs_0024.h5\")\n",
    "# COCO_MODEL_PATH_ALL= os.path.join(ROOT_DIR, \"mask_rcnn_road_signs_0030.h5\")\n",
    "COCO_MODEL_PATH_ALL= os.path.join(ROOT_DIR, \"mask_rcnn_road_signs_0030_all_data_all_layers.h5\")\n",
    "# COCO_MODEL_PATH_ALL= os.path.join(ROOT_DIR, \"mask_rcnn_road_signs_0030_SN_data_head_layers.h5\")\n",
    "# COCO_MODEL_PATH_ALL= os.path.join(ROOT_DIR, \"mask_rcnn_road_signs_0020_SN_data_4_layers_0_001lr.h5\")\n",
    "# COCO_MODEL_PATH_ALL= os.path.join(ROOT_DIR, \"mask_rcnn_road_signs_0027_SN_data_all_layers.h5\")\n",
    "\n",
    "# Download COCO trained weights from Releases if needed\n",
    "# if not os.path.exists\n",
    "\n",
    "(COCO_MODEL_PATH):\n",
    "#     utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "#IMAGE_DIR = os.path.join(ROOT_DIR, \"Mask_RCNN/samples/roadsigns/signs_dataset/\")\n",
    "\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, \"Mask_RCNN/samples/roadsigns/signs_dataset_01/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InferenceConfigAll(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # single sign detect\n",
    "    NUM_CLASSES = 1 + 1  # 1 Background + 1 Building\n",
    "    \n",
    "    # detect signs by type\n",
    "    #NUM_CLASSES = 1 + 35  # 1 Background + 1 Building\n",
    "    #IMAGE_MAX_DIM=320\n",
    "    #IMAGE_MIN_DIM=320\n",
    "configAll = InferenceConfigAll()\n",
    "#config.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create model object in inference mode.\n",
    "model_all = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=configAll)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model_all.load_weights(COCO_MODEL_PATH_ALL, by_name=True)\n",
    "#model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[ \"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "#model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[ \"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class_names_all = ['BG', 'road_sign']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "your_path = \"D:/TEMP/_deeplearning/road_signs/_video_25_01_2020/out_image/VID_20200125_160419_01752.jpg\"\n",
    "\n",
    "# your_path = \"D:/TEMP/_deeplearning/__from_kiev/1.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "size = os.path.getsize(your_path)\n",
    "filename = os.path.basename(your_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_all = skimage.io.imread(your_path)\n",
    "# Run detection\n",
    "results_all = model_all.detect([image_all], verbose=1)\n",
    "\n",
    "# Visualize results\n",
    "r_all = results_all[0]\n",
    "visualize.display_instances(image_all, r_all['rois'], r_all['masks'], r_all['class_ids'], class_names_all, r_all['scores'])\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_colors(N):\n",
    "    np.random.seed(1)\n",
    "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
    "    return colors\n",
    "\n",
    "def apply_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"apply mask to image\"\"\"\n",
    "    for n, c in enumerate(color):\n",
    "        image[:, :, n] = np.where(\n",
    "            mask == 1,\n",
    "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
    "            image[:, :, n]\n",
    "        )\n",
    "    return image\n",
    "\n",
    "def display_instances(image, boxes, masks, ids, names, scores):\n",
    "    \"\"\"\n",
    "        take the image and results and apply the mask, box, and Label\n",
    "    \"\"\"\n",
    "    n_instances = boxes.shape[0]\n",
    "    colors = random_colors(n_instances)\n",
    "\n",
    "    if not n_instances:\n",
    "        print('NO INSTANCES TO DISPLAY')\n",
    "    else:\n",
    "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "        if not np.any(boxes[i]):\n",
    "            continue\n",
    "\n",
    "        y1, x1, y2, x2 = boxes[i]\n",
    "        label = names[ids[i]]\n",
    "        score = scores[i] if scores is not None else None\n",
    "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
    "        mask = masks[:, :, i]\n",
    "\n",
    "        image = apply_mask(image, mask, color)\n",
    "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
    "        image = cv2.putText(\n",
    "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
    "        )\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_all = skimage.io.imread(your_path)\n",
    "# Run detection\n",
    "results_all = model_all.detect([image_all], verbose=1)\n",
    "\n",
    "# Visualize results\n",
    "r_all = results_all[0]\n",
    "color_img = display_instances(image_all, r_all['rois'], r_all['masks'], r_all['class_ids'], class_names_all, r_all['scores'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "from pycocotools import mask\n",
    "from skimage.filters import threshold_otsu\n",
    "from scipy.spatial import ConvexHull\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "import time\n",
    "save_path = r'C:\\Users\\Administrator\\Image-Classification-by-Keras-and-Tensorflow-master\\Using Tensorflow\\data\\save'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_all = skimage.io.imread(your_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "i = 0\n",
    "dim = (128, 128)\n",
    "for val in r_all['rois']:\n",
    "    im_croped = []\n",
    "    # print(val[0], val[2], val[1], val[3])\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # Идея вырезать картинки не по ббокс а по контуру маски. \n",
    "    # Будет ли так работать предсказание точнее?\n",
    "    \n",
    "    masks = r_all['masks'][:, :, i]\n",
    "    ground_truth_binary_mask = masks\n",
    "    contours = measure.find_contours(ground_truth_binary_mask, 0.5)\n",
    "    hull = ConvexHull(contours[0])\n",
    "    polygon =[]\n",
    "    for v in hull.vertices:\n",
    "        pt = []\n",
    "        # print(contours[0][v][0], contours[0][v][1])\n",
    "        pt.append(int(contours[0][v][0]))\n",
    "        pt.append(int(contours[0][v][1]))\n",
    "        polygon.append(pt)\n",
    "    pts = np.array(polygon)\n",
    "    # print (pts)\n",
    "    rect = cv2.boundingRect(pts)\n",
    "    y, x, w, h = rect\n",
    "    croped = image_all[y:y+w, x:x+h].copy()\n",
    "    pts = pts - pts.min(axis=0)\n",
    "    pts = np.flip(pts,1)\n",
    "    # print (pts)\n",
    "\n",
    "    mask = np.zeros(croped.shape[:2], np.uint8)\n",
    "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "    ## (3) do bit-op\n",
    "    dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
    "\n",
    "    ## (4) add the white background\n",
    "    bg = np.ones_like(croped, np.uint8) * 255\n",
    "    cv2.bitwise_not(bg, bg, mask=mask)\n",
    "    dst2 = bg + dst\n",
    "    dim = (128, 128)\n",
    "    dst2 = cv2.resize(dst2, dim, interpolation=cv2.INTER_AREA)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(dst2)\n",
    "    im_path = save_path + '\\image_' + str(i) + '.png'\n",
    "    scipy.misc.imsave(im_path, dst2)\n",
    "    \n",
    "    # ---------------------------------------------\n",
    "    # Старый код\n",
    "    \n",
    "    # cropped = image_all[val[0]:val[2],val[1]:val[3]]\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(cropped)\n",
    "    # im_path = save_path + '\\image_' + str(i) + '.png'\n",
    "    # cropped = cv2.resize(cropped, dim, interpolation=cv2.INTER_AREA)\n",
    "    # scipy.misc.imsave(im_path, cropped)\n",
    "    \n",
    "    i = i + 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    start = time.time()\n",
    "\n",
    "# try:\n",
    "    \n",
    "# Path of  training images\n",
    "train_path = r'C:\\Users\\Administrator\\Image-Classification-by-Keras-and-Tensorflow-master\\Using Tensorflow\\data\\train'\n",
    "if not os.path.exists(train_path):\n",
    "    print(\"No such directory\")\n",
    "    raise Exception\n",
    "# Path of testing images\n",
    "dir_path = r'C:\\Users\\Administrator\\Image-Classification-by-Keras-and-Tensorflow-master\\Using Tensorflow\\data\\save'\n",
    "if not os.path.exists(dir_path):\n",
    "    print(\"No such directory\")\n",
    "    raise Exception\n",
    "\n",
    "# Walk though all testing images one by one\n",
    "for root, dirs, files in os.walk(dir_path):\n",
    "    for name in files:\n",
    "\n",
    "        print(\"\")\n",
    "        image_path = name\n",
    "        filename = dir_path +'\\\\' +image_path\n",
    "        print(filename)\n",
    "        image_size=128\n",
    "        num_channels=3\n",
    "        images = []\n",
    "\n",
    "        if os.path.exists(filename):\n",
    "\n",
    "            # Reading the image using OpenCV\n",
    "            image = cv2.imread(filename)\n",
    "            # Resizing the image to our desired size and preprocessing will be done exactly as done during training\n",
    "            image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "            images.append(image)\n",
    "            images = np.array(images, dtype=np.uint8)\n",
    "            images = images.astype('float32')\n",
    "            images = np.multiply(images, 1.0/255.0)\n",
    "\n",
    "            # The input to the network is of shape [None image_size image_size num_channels]. Hence we reshape.\n",
    "            x_batch = images.reshape(1, image_size,image_size,num_channels)\n",
    "\n",
    "            # Let us restore the saved model\n",
    "            sess = tf.Session()\n",
    "            # Step-1: Recreate the network graph. At this step only graph is created.\n",
    "            saver = tf.train.import_meta_graph('C:/Users/Administrator/Image-Classification-by-Keras-and-Tensorflow-master/Using Tensorflow/models/model.meta')\n",
    "            # Step-2: Now let's load the weights saved using the restore method.\n",
    "            saver.restore(sess, tf.train.latest_checkpoint('C:/Users/Administrator/Image-Classification-by-Keras-and-Tensorflow-master/Using Tensorflow/models/'))\n",
    "\n",
    "            # Accessing the default graph which we have restored\n",
    "            graph = tf.get_default_graph()\n",
    "\n",
    "            # Now, let's get hold of the op that we can be processed to get the output.\n",
    "            # In the original network y_pred is the tensor that is the prediction of the network\n",
    "            y_pred = graph.get_tensor_by_name(\"y_pred:0\")\n",
    "\n",
    "            ## Let's feed the images to the input placeholders\n",
    "            x= graph.get_tensor_by_name(\"x:0\")\n",
    "            y_true = graph.get_tensor_by_name(\"y_true:0\")\n",
    "            y_test_images = np.zeros((1, len(os.listdir(train_path))))\n",
    "\n",
    "\n",
    "            # Creating the feed_dict that is required to be fed to calculate y_pred\n",
    "            feed_dict_testing = {x: x_batch, y_true: y_test_images}\n",
    "            result=sess.run(y_pred, feed_dict=feed_dict_testing)\n",
    "            # Result is of this format [[probabiliy_of_classA probability_of_classB ....]]\n",
    "            print(result)\n",
    "\n",
    "            # Convert np.array to list\n",
    "            a = result[0].tolist()\n",
    "            r=0\n",
    "\n",
    "            # Finding the maximum of all outputs\n",
    "            max1 = max(a)\n",
    "            index1 = a.index(max1)\n",
    "            predicted_class = None\n",
    "\n",
    "            # Walk through directory to find the label of the predicted output\n",
    "            count = 0\n",
    "            for root, dirs, files in os.walk(train_path):\n",
    "                for name in dirs:\n",
    "                    if count==index1:\n",
    "                        predicted_class = name\n",
    "                    count+=1\n",
    "\n",
    "            # If the maximum confidence output is largest of all by a big margin then\n",
    "            # print the class or else print a warning\n",
    "            for i in a:\n",
    "                if i!=max1:\n",
    "                    if max1-i<i:\n",
    "                        r=1\n",
    "            if r ==0:\n",
    "                print(predicted_class)\n",
    "            else:\n",
    "                print(\"Could not classify with definite confidence\")\n",
    "                # print(\"Maybe:\",predicted_class)\n",
    "\n",
    "        # If file does not exist\n",
    "        else:\n",
    "            print(\"File does not exist\")\n",
    "                \n",
    "# except Exception as e:\n",
    "#     print(\"Exception:\",e)\n",
    "\n",
    "# Calculate execution time\n",
    "end = time.time()\n",
    "dur = end-start\n",
    "print(\"\")\n",
    "if dur<60:\n",
    "    print(\"Execution Time:\",dur,\"seconds\")\n",
    "elif dur>60 and dur<3600:\n",
    "    dur=dur/60\n",
    "    print(\"Execution Time:\",dur,\"minutes\")\n",
    "else:\n",
    "    dur=dur/(60*60)\n",
    "    print(\"Execution Time:\",dur,\"hours\")\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
